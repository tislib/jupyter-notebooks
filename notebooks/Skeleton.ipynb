{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run '../main.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetOps = DataSetOps()\n",
    "\n",
    "dataSetOps.import_years(2014, 2017)\n",
    "\n",
    "dataSetOps.prepare()\n",
    "dataSetOps.prepare2()\n",
    "\n",
    "df = dataSetOps.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>close</th>\n",
       "      <th>price</th>\n",
       "      <th>diff</th>\n",
       "      <th>value_d</th>\n",
       "      <th>mavg10</th>\n",
       "      <th>mavg20</th>\n",
       "      <th>...</th>\n",
       "      <th>val_past_60</th>\n",
       "      <th>val_past_61</th>\n",
       "      <th>val_past_62</th>\n",
       "      <th>val_past_63</th>\n",
       "      <th>has_down_v</th>\n",
       "      <th>has_up_v</th>\n",
       "      <th>has_down</th>\n",
       "      <th>has_up</th>\n",
       "      <th>has_not_up</th>\n",
       "      <th>value_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>20140102 100700</td>\n",
       "      <td>1.36572</td>\n",
       "      <td>1.36584</td>\n",
       "      <td>1.36554</td>\n",
       "      <td>1.36554</td>\n",
       "      <td>1.36554</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.695</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>20140102 100800</td>\n",
       "      <td>1.36550</td>\n",
       "      <td>1.36555</td>\n",
       "      <td>1.36522</td>\n",
       "      <td>1.36555</td>\n",
       "      <td>1.36555</td>\n",
       "      <td>-0.00020</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>20140102 100900</td>\n",
       "      <td>1.36554</td>\n",
       "      <td>1.36556</td>\n",
       "      <td>1.36532</td>\n",
       "      <td>1.36535</td>\n",
       "      <td>1.36535</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>4.055</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>20140102 101000</td>\n",
       "      <td>1.36536</td>\n",
       "      <td>1.36575</td>\n",
       "      <td>1.36524</td>\n",
       "      <td>1.36575</td>\n",
       "      <td>1.36575</td>\n",
       "      <td>-0.00020</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>7.500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>20140102 101100</td>\n",
       "      <td>1.36576</td>\n",
       "      <td>1.36576</td>\n",
       "      <td>1.36525</td>\n",
       "      <td>1.36532</td>\n",
       "      <td>1.36532</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>3.025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date     open      max      min    close    price     diff  \\\n",
       "999   20140102 100700  1.36572  1.36584  1.36554  1.36554  1.36554 -0.00003   \n",
       "1000  20140102 100800  1.36550  1.36555  1.36522  1.36555  1.36555 -0.00020   \n",
       "1001  20140102 100900  1.36554  1.36556  1.36532  1.36535  1.36535  0.00001   \n",
       "1002  20140102 101000  1.36536  1.36575  1.36524  1.36575  1.36575 -0.00020   \n",
       "1003  20140102 101100  1.36576  1.36576  1.36525  1.36532  1.36532  0.00040   \n",
       "\n",
       "      value_d  mavg10  mavg20    ...     val_past_60  val_past_61  \\\n",
       "999      -0.3    6.71   6.695    ...            -1.2         -1.8   \n",
       "1000     -2.0    6.11   6.430    ...            -0.8         -1.2   \n",
       "1001      0.1    3.27   4.055    ...             1.9         -0.8   \n",
       "1002     -2.0    5.41   7.500    ...             3.1          1.9   \n",
       "1003      4.0   -0.05   3.025    ...             1.3          3.1   \n",
       "\n",
       "      val_past_62  val_past_63  has_down_v  has_up_v  has_down  has_up  \\\n",
       "999           0.5          3.2         NaN       NaN     False   False   \n",
       "1000         -1.8          0.5         NaN       NaN     False   False   \n",
       "1001         -1.2         -1.8         NaN       NaN     False   False   \n",
       "1002         -0.8         -1.2         NaN       NaN     False   False   \n",
       "1003          1.9         -0.8         NaN       NaN     False   False   \n",
       "\n",
       "      has_not_up  value_nr  \n",
       "999        False     False  \n",
       "1000       False     False  \n",
       "1001       False     False  \n",
       "1002       False     False  \n",
       "1003       False     False  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6d81d8978>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.value_nr.astype(int).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['value_d', 'mavg10', 'mavg20', 'mavg100', 'mavg1000']]\n",
    "Y = df['value_nr']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=5, units=64, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/taleh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2130 - mean_absolute_error: 0.4257\n",
      "Epoch 2/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2124 - mean_absolute_error: 0.4246\n",
      "Epoch 3/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2123 - mean_absolute_error: 0.4244\n",
      "Epoch 4/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2122 - mean_absolute_error: 0.4243\n",
      "Epoch 5/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2122 - mean_absolute_error: 0.4242\n",
      "Epoch 6/100\n",
      "1185442/1185442 [==============================] - 60s 50us/step - loss: 0.2122 - mean_absolute_error: 0.4242\n",
      "Epoch 7/100\n",
      "1185442/1185442 [==============================] - 61s 51us/step - loss: 0.2122 - mean_absolute_error: 0.4242\n",
      "Epoch 8/100\n",
      "1185442/1185442 [==============================] - 62s 52us/step - loss: 0.2122 - mean_absolute_error: 0.4243\n",
      "Epoch 9/100\n",
      "1185442/1185442 [==============================] - 59s 50us/step - loss: 0.2122 - mean_absolute_error: 0.4242\n",
      "Epoch 10/100\n",
      "1185442/1185442 [==============================] - 60s 51us/step - loss: 0.2121 - mean_absolute_error: 0.4241\n",
      "Epoch 11/100\n",
      "1185442/1185442 [==============================] - 61s 52us/step - loss: 0.2122 - mean_absolute_error: 0.4243\n",
      "Epoch 12/100\n",
      " 377110/1185442 [========>.....................] - ETA: 41s - loss: 0.2122 - mean_absolute_error: 0.4243"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f4ca42439cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Fitting our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Initializing Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu', input_dim = 5))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling Neural Network\n",
    "from keras import metrics\n",
    "metric_names = [metrics.mae]\n",
    "classifier.compile(optimizer='adam', loss = 'mean_squared_error', metrics=metric_names)\n",
    "\n",
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.helper import AccuracyCalculator\n",
    "\n",
    "AccuracyCalculator.class_accuracy(cm)\n",
    "AccuracyCalculator.optimistic_accuracy(classifier.predict(X_test)[:,0], y_test, 100)\n",
    "risk_hist_df = AccuracyCalculator.risk_hist(classifier.predict(X_test)[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_hist_df.risk.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
