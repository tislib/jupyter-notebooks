{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run '../main.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetOps = DataSetOps()\n",
    "\n",
    "dataSetOps.import_years(2016, 2017)\n",
    "\n",
    "dataSetOps.prepare()\n",
    "dataSetOps.prepare2()\n",
    "\n",
    "df = dataSetOps.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>close</th>\n",
       "      <th>price</th>\n",
       "      <th>diff</th>\n",
       "      <th>value_d</th>\n",
       "      <th>mavg10</th>\n",
       "      <th>mavg20</th>\n",
       "      <th>...</th>\n",
       "      <th>val_past_60</th>\n",
       "      <th>val_past_61</th>\n",
       "      <th>val_past_62</th>\n",
       "      <th>val_past_63</th>\n",
       "      <th>has_down_v</th>\n",
       "      <th>has_up_v</th>\n",
       "      <th>has_down</th>\n",
       "      <th>has_up</th>\n",
       "      <th>has_not_up</th>\n",
       "      <th>value_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>20160104 094200</td>\n",
       "      <td>1.08547</td>\n",
       "      <td>1.08556</td>\n",
       "      <td>1.08529</td>\n",
       "      <td>1.08543</td>\n",
       "      <td>1.08543</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>20160104 094300</td>\n",
       "      <td>1.08542</td>\n",
       "      <td>1.08557</td>\n",
       "      <td>1.08532</td>\n",
       "      <td>1.08553</td>\n",
       "      <td>1.08553</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.175</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>20160104 094400</td>\n",
       "      <td>1.08553</td>\n",
       "      <td>1.08555</td>\n",
       "      <td>1.08538</td>\n",
       "      <td>1.08546</td>\n",
       "      <td>1.08546</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.595</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>20160104 094500</td>\n",
       "      <td>1.08545</td>\n",
       "      <td>1.08549</td>\n",
       "      <td>1.08493</td>\n",
       "      <td>1.08493</td>\n",
       "      <td>1.08493</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-3.465</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>20160104 094600</td>\n",
       "      <td>1.08487</td>\n",
       "      <td>1.08503</td>\n",
       "      <td>1.08484</td>\n",
       "      <td>1.08503</td>\n",
       "      <td>1.08503</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-2.465</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date     open      max      min    close    price     diff  \\\n",
       "999   20160104 094200  1.08547  1.08556  1.08529  1.08543  1.08543  0.00020   \n",
       "1000  20160104 094300  1.08542  1.08557  1.08532  1.08553  1.08553 -0.00005   \n",
       "1001  20160104 094400  1.08553  1.08555  1.08538  1.08546  1.08546  0.00010   \n",
       "1002  20160104 094500  1.08545  1.08549  1.08493  1.08493  1.08493 -0.00007   \n",
       "1003  20160104 094600  1.08487  1.08503  1.08484  1.08503  1.08503 -0.00053   \n",
       "\n",
       "      value_d  mavg10  mavg20    ...     val_past_60  val_past_61  \\\n",
       "999       2.0    0.72   1.100    ...             6.0         -0.9   \n",
       "1000     -0.5    1.57   2.175    ...             1.4          6.0   \n",
       "1001      1.0    1.37   1.595    ...             1.7          1.4   \n",
       "1002     -0.7   -3.43  -3.465    ...            -5.8          1.7   \n",
       "1003     -5.3   -2.26  -2.465    ...            -4.2         -5.8   \n",
       "\n",
       "      val_past_62  val_past_63  has_down_v  has_up_v  has_down  has_up  \\\n",
       "999          -3.2         -5.4         NaN       NaN     False   False   \n",
       "1000         -0.9         -3.2         NaN       NaN     False   False   \n",
       "1001          6.0         -0.9         NaN       NaN     False   False   \n",
       "1002          1.4          6.0         NaN       NaN     False   False   \n",
       "1003          1.7          1.4         NaN       NaN     False   False   \n",
       "\n",
       "      has_not_up  value_nr  \n",
       "999        False     False  \n",
       "1000       False     False  \n",
       "1001       False     False  \n",
       "1002       False     False  \n",
       "1003       False     False  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fac5ae20978>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.value_nr.astype(int).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['value_d', 'mavg10', 'mavg20', 'mavg100', 'mavg1000']]\n",
    "Y = df['value_nr']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-77409dc08c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Fitting our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m# to match the value shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mchild_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Activation\n",
    "\n",
    "#Initializing Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu', input_dim = 5))\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "# # Adding the second hidden layer\n",
    "# classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "hidden_size = 64\n",
    "\n",
    "classifier.add(LSTM(5))\n",
    "# if use_dropout:\n",
    "#     model.add(Dropout(0.5))\n",
    "classifier.add(TimeDistributed(Dense(5)))\n",
    "classifier.add(Activation('softmax'))\n",
    "\n",
    "# Compiling Neural Network\n",
    "from keras import metrics\n",
    "metric_names = [metrics.mae]\n",
    "classifier.compile(optimizer='adam', loss = 'mean_squared_error', metrics=metric_names)\n",
    "\n",
    "# Fitting our model \n",
    "train = np.reshape(X_train,(X_train.shape[0], 1, X_train.shape[1]))\n",
    "classifier.fit(train, y_train, batch_size = 10, epochs = 3)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.helper import AccuracyCalculator\n",
    "\n",
    "AccuracyCalculator.class_accuracy(cm)\n",
    "AccuracyCalculator.optimistic_accuracy(classifier.predict(X_test)[:,0], y_test, 100)\n",
    "risk_hist_df = AccuracyCalculator.risk_hist(classifier.predict(X_test)[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_hist_df.risk.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
